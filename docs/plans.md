**–ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞:**

### 1. **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤**
- **–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å**: 
  - **GPT-2 Small** (–∏–ª–∏ **DistilGPT2**) ‚Äî –ª–µ–≥–∫–∞—è, –±—ã—Å—Ç—Ä–æ –æ–±—É—á–∞–µ—Ç—Å—è, –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –Ω–æ—É—Ç–±—É–∫–æ–≤.
  - –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: **TinyLlama** (1.1B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤) –∏–ª–∏ **Microsoft Phi-3-mini** (3.8B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤), –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç VRAM.
- **–§—Ä–µ–π–º–≤–æ—Ä–∫–∏**: 
  - **Hugging Face Transformers** (–¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏), 
  - **PyTorch** (–æ–±—É—á–µ–Ω–∏–µ), 
  - **Google Colab** (–µ—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ).

---

### 2. **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö**
- **–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö**:
  - –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø–µ—Ä–µ–ø–∏—Å–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ Telegram –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON).
  - –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö: 
    ```json
    {"messages": [
      {"user": "–ü—Ä–∏–≤–µ—Ç!", "bot": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π!"},
      {"user": "–ö–∞–∫ –¥–µ–ª–∞?", "bot": "–ù–æ—Ä–º, —Å–∞–º –∫–∞–∫?"}
    ]}
    ```
- **–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞**:
  - –û—á–∏—Å—Ç–∫–∞ –æ—Ç —ç–º–æ–¥–∑–∏, —Å—Å—ã–ª–æ–∫, —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
  - –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:  
    ```python
    "User: –ü—Ä–∏–≤–µ—Ç!\nBot: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π!\nUser: –ö–∞–∫ –¥–µ–ª–∞?\nBot: –ù–æ—Ä–º, —Å–∞–º –∫–∞–∫?"
    ```
  - –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º `GPT2Tokenizer`.

---

### 3. **–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏**
#### –í–∞—Ä–∏–∞–Ω—Ç 1: **–ë–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è (Prompt Engineering)**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ —Å—Ç–∏–ª–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ –ø—Ä–æ–º–ø—Ç—ã.
- –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞:
  ```
  "–û—Ç–≤–µ—Ç—å –∫–∞–∫ —è. –ú–æ–π —Å—Ç–∏–ª—å: –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã, —Å–º–∞–π–ª–∏–∫–∏ üòä. –î–∏–∞–ª–æ–≥:
  User: –ü—Ä–∏–≤–µ—Ç!
  Bot: –ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —Å–∞–º?
  User: {–∑–∞–ø—Ä–æ—Å}
  Bot:"
  ```
- **–ü–ª—é—Å—ã**: –ù–µ —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è, —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–∞–∂–µ –Ω–∞ CPU.

#### –í–∞—Ä–∏–∞–Ω—Ç 2: **–î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏**
- **–®–∞–≥–∏**:
  1. –†–∞–∑–±–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ/–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ (80/20%).
  2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å LoRA (Low-Rank Adaptation) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–æ—É—Ç–±—É–∫–µ.
  3. –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
     ```python
     training_args = TrainingArguments(
         per_device_train_batch_size=2,  # –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
         num_train_epochs=3,
         learning_rate=5e-5,
         fp16=True  # –µ—Å–ª–∏ GPU –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
     )
     ```
  4. –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å:
     ```python
     trainer = Trainer(model=model, args=training_args, train_dataset=train_data)
     trainer.train()
     ```
- **–ü–ª—é—Å—ã**: –ë–æ–ª–µ–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã.

---

### 4. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**
- **–ú–µ—Ç—Ä–∏–∫–∏**:
  - **Perplexity** (—á–µ–º –Ω–∏–∂–µ, —Ç–µ–º –ª—É—á—à–µ) ‚Äî –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏.
  - **ROUGE-L** ‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
  - **–ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞** (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ –æ–ø—Ä–æ—Å–Ω–∏–∫: "–ù–∞—Å–∫–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –ø–æ—Ö–æ–∂ –Ω–∞ –≤–∞—à —Å—Ç–∏–ª—å?").
- **–ü—Ä–∏–º–µ—Ä —Ç–µ—Å—Ç–∞**:
  ```
  –í—Ö–æ–¥: "–ß—Ç–æ –¥–µ–ª–∞–µ—à—å?"
  –û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç: "–ù–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ, –ø—Ä–æ—Å—Ç–æ –æ—Ç–¥—ã—Ö–∞—é üòé"
  –í–∞—Ä–∏–∞–Ω—Ç 1 (–±–µ–∑ –æ–±—É—á–µ–Ω–∏—è): "–Ø —Ä–∞–±–æ—Ç–∞—é –Ω–∞–¥ –ø—Ä–æ–µ–∫—Ç–æ–º."
  –í–∞—Ä–∏–∞–Ω—Ç 2 (—Å –æ–±—É—á–µ–Ω–∏–µ–º): "–ù–∏—á–µ–≥–æ, –≤–∞–ª—è—é—Å—å –Ω–∞ –¥–∏–≤–∞–Ω–µ üòé"
  ```

---

### 5. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–ª–∞–±–æ–≥–æ –∂–µ–ª–µ–∑–∞**
- **–ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏**:
  ```python
  model = quantize_model(model, qconfig=default_qconfig)  # —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏ –≤ 4 —Ä–∞–∑–∞.
  ```
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ONNX Runtime** –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.
- **–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —á–µ–∫–∏–Ω–≥** (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏):
  ```python
  training_args.gradient_checkpointing = True
  ```

---

### 6. **–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å**
- **Telegram-–±–æ—Ç** (–Ω–∞ –±–∞–∑–µ python-telegram-bot):
  - –ö–æ–º–∞–Ω–¥–∞ `/train` ‚Äî –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
  - –ö–æ–º–∞–Ω–¥–∞ `/generate` ‚Äî –æ—Ç–≤–µ—Ç –≤ —Å—Ç–∏–ª–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
- –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞:
  ```python
  from telegram import Update
  from telegram.ext import Application, CommandHandler

  async def generate(update: Update, context):
      response = model.generate(update.message.text)
      await update.message.reply_text(response)

  app = Application.builder().token("TOKEN").build()
  app.add_handler(CommandHandler("generate", generate))
  app.run_polling()
  ```

---

### 7. **–°—Ç–µ–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π**
```
Python 3.10+
‚îú‚îÄ‚îÄ Transformers (Hugging Face)
‚îú‚îÄ‚îÄ PyTorch
‚îú‚îÄ LoRA (peft)
‚îú‚îÄ Datasets (–¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏)
‚îî‚îÄ ONNX Runtime (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
```

---

**–ò—Ç–æ–≥**: 
- –î–ª—è **—É—á–µ–±–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞** –ª—É—á—à–µ –Ω–∞—á–∞—Ç—å —Å **LoRA + GPT-2 Small** ‚Äî —ç—Ç–æ –¥–∞—Å—Ç –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é. 
- –ï—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ—É—Ç–±—É–∫–µ —Ç–æ—Ä–º–æ–∑–∏—Ç, –º–æ–∂–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ **Google Colab** (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π T4 GPU). 
- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–∏—Ç—å —á–µ—Ä–µ–∑ ROUGE-L –∏ –≤–∏–∑—É–∞–ª—å–Ω–æ (–ø—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤).